---
title: Stocahstic Hypercube Sample
author: Tim Menzies
excerpt: Poke a little, prune a little, stretch a little
layout: post
---

We write to suggest that the range of services
usually offered by search-based software engineering
(SBSE) tools should be extended.  To understand the
range of usually services, we look to the core
definitions of recent survey articles.
[Harman et al.][harman12dec] are kind enough to
oblidge.  They note that what makes SBSE so useful
is that it supports the optimization of standard
SBSE tools ``without the need for the simulation and
modeling inherent in all other approaches to
engineering optimization.''. To explain that remark,
we offer the distinction between:

[harman12dec]: http://menzies.us 'asdasasasasddasdsa'

+ _Model-based_ methods that require detailed descriptions of all aspects of the system under study;
+ _Instance-based_ methods that can work with the observed examples, without needing much
  detail on how those instances were generated.

One example of _model-based methods_ (that are hard
to commission for complex SE applications) would be
any gradient descent method that demands models of
real-valued functions that are a differentiable
(i.e. derivative exists at each point in its
domain). For such simple models, it is relatively
easy to reflect on the partial derivatives to
determine the next best direction to
try. Unfortunately, software are intricate
combinations of real-valued and discrete-valued
systems. Also, their internal state space may not be
smoothly differentiable (every _if_ statement
divides that space into different regions with
different properties). Further, in the case of
mash-ups from different suppliers, it is not even
true that those internal details are
accessible. Worse yet, even if they were accessible,
then it can take much effort to understand all those
internal details and translate them into a format
suitable for the particular SBSE tool. And lastly,
even if all the hurdles are surpassed, there remains
the NP-hard task of trading off between three or
more competing goals (where improving on one goal
means having to trade-off on one of the others).

On the other hand, an example of an _instance-based_
method would be a standard SBSE tasks of (say)
[parameter tuning for a data mining algorithm][cora10].
In this case, there is:

+ Some black-box device; e.g. the data miner;
+ With _decisions_ we can manipulate; e.g. in [random forests][briemann01], how many
  trees to add to the forest;
+ And some _objectives_ to be minimized or maximized; e.g. decrease false alarm
  rates, increase precision and recall, increase the
  number of examples that are covered by the final
  model; decrease the size of the learned model (since humans find such
  smaller models easier to understand).

So that is the usual instance-based SBSE approach : some black box (with
input decisions we can manipulate) which executes
and automatically generates output values that we
can evaluate even if the analyst does not understand
all the details of that process. 

## Aside: Are all Models so Hard to Understand?

The above text praised the way instance-based SBSE methods can reason
about models without the analyst knowing all the internal details
of those models.
Lest the reader is nervous
that we are abdicating our responsibility to understand the models being studied,
we hasten to add that all such understanding is inherently limited.

One of the earliest adopters of this kind of analysis was John von Neumann in the 1940s
who  was well-versed in the work
of  G&ouml; and  Turing (G&ouml;odel had an office two doors down from von Neumann and,
with his team of engineers, von Nuemann had read Turing's work so
often that those books were [falling apart in their library][dyson12]).
Von Nuemann knew that
the incompleteness and the halting problem meant that, in the end, we cannot
always accurately
predict the consequences of the interactions between axioms in software.
In  essence, he  realized that {\em rationality had become an experimental science}
and the only way to really test the implications of a model, was to run it and watch
what happens.

Levens models example

Our first study is a small thought experiment. The reader is invited to maintain a one-line
mathematical model of exponential population growth:

EQ1 : dN/dT = rN.

In EQ1, r is a constant reflecting environmental conditions, T is time, and N is the
population. Note that this model is wrong72 since population growth must taper off as it
approaches C the maximum carrying capacity of the environment; i.e.

EQ2 : dN/dT = rN(1-(N/C)).

If the reader can correctly answer the following question, then we have anecdotal
evidence for believing that humans can read and critique models: is EQ2 correct? If
the reader cannot find all errors in a one-line model (which they probably studied
extensively in high school), then we should be suspicious of claims that the truth status
of larger models can be accurately determined by people.

EQ2 is incorrect. In the case of a hostile environment and over-population, N > C, r <
0, and our intuition is that the population will fall. However,rN(1-(N/C)) > 0; i.e. the
maths says that population will increase. (example from [207]). Our experience has been
that the error is not apparent to many people. Note that we have failed to ascertain the
truth status of a one-line mathematical model.


## Back

which automatically generates 

Must be instance-based

Let _N_ = 50 (say).

Generate  a crowd of _N_ random examples, for each, find the distance to all other points.

As you do distances, keep a track of all the distances seen so we can learn what _close_ means
(e.g. in the following, see the _cl_ variable:


```python
def poke():
  cl=Close()
  for one in crowd:
    one.neighbors=[]
  for one in crowd:
    for two in crowd:
  	  if id(one) > id(two):
        d = dist(one,two)
        cl += d
  		  one.neighbors += [(d,two)]
  	    two.neighbors += [(d,one)]
  for one in crowd:
    one.neighbors= sorted(one.neighbors)
```

Here is  the code for _Close_ used by the _cl_ tracking variable:

```python

class Close():
	tiny=0.05
	enough=20
  def __init__(i):
    i.sum, i.n = [0]*32, [0]*32
  def p(i,x):
    for j in xrange(len(i.sum)):
      mu = i.sum[j] / i.n[j]
      if x > mu:
        return i.n[j]/i.n[0]
    return i.n[-1]/i.n[0]
  def __iadd__(i,x):
    for j in xrange(len(i.sum)):
      i.sum[j] += x
      i.n[j]   += 1
      mu        = i.sum[j] / i.n[j]
      if x >= mu: return i
      if i.sum[j] < Close.enough: return i
    return i
  def close(i,x):
    return i.p(x) < Close.enough
```

Let  _crowded_ be all the items are very close to their nearest neighbor. 
Shuffle the list of crowdeds.

Let _lonelies_ be all the items who are very far from their neasrest neighbor.
Shuffle the list of lonlies.

Now it is time for _pruneStretch_ where, a random number of times we do either:

+ _Prune_: Pick the first crowded item and  fuse it with its nearest neighbor.
Add a pointer to that crowded item noting that it has been fused to the new item
(so really, before fusing, check that that _fused_ pointer is non-nil and it if isn't follow
the fused chain to the last  fused thing). If each raw item has weight one,
thenthe fused items have a weight equal to the sum of their fused weights. When fusing two
items, create a new item that os proportionally weighted to the two old items.

+ _Stretch_: Pick the first lonely and create one new item halfway to its nearest neighbor.

Now start leapfrogging. Add all points to a list of _zombies_. Then a random number of times:

+ Pick any zombie _Z_
+ Find _Y_, which is any point closish to _Z_ (note, near enough is good enough
  and during that calculation, 
  keep track of the distances in _cl_).
+ If Y is evaluated and Y.dead and close to Z then then also Z.dead. Go back to picking a new Z.
+ Otherwise, make sure we have evalauted Y,Z.
+ Ensure Y,Z are evaluated and check for dominance.
  Each undominated member of (Y,Z) will be now alive and any others will be dead.
+ If Y,Z have one alive and dead then extrapolate from dead to alive to make new point W.
  Add W to the list of zombies.

Now you have a new population. Delete all neighbor lists and fuse pointers. Go back to _poke_.
